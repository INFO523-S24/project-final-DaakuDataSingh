---
title: "Project Title"
subtitle: "INFO 523 - Project Final"
author: 
  - name: "Team name - Team member 1, Team member 2,..."
    affiliations:
      - name: "School of Information, University of Arizona"
description: "Project description"
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
  echo: false
jupyter: python3
---

## Abstract

Add project abstract here.


## Introduction
```{python}

```

## EDA
```{python}

```

## Data Cleaning
```{python}

```

## Feature Engineering
```{python}

```

## Feature Selection
```{python}

```

## Model Training (Logit)
```{python}

```

## Model Validation
```{python}

```

## Alternative Models
```{python}

```

### Decision Tree Classifier
```{python}

```

### Random Forest Classifier
```{python}

```

## Model Comparison and Selection
```{python}

```

## Model Implementation with Dashboard
```{python}

```

### Datasets & question
Based on a county's demographic, employment, and household data, can we predict whether the median price for center-based childcare for preschoolers (mc_preschool) will be above or below the state's average?
- [**Childcare costs**](https://github.com/rfordatascience/tidytuesday/tree/master/data/2023/2023-05-09)

---

## Part 1: Data Preparation and Exploration

### Task 1: Data Retrieval
- Download the dataset provided for the week from the TidyTuesday repository.
- Load the dataset into a Python environment using pandas.

### Task 2: Exploratory Data Analysis (EDA)
- Perform EDA to understand the features of the dataset.
- Visualize the distribution of the classes (target variable).
- Identify and visualize relationships between features and the target variable.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Use `matplotlib` and `seaborn` for visualizations to understand data distributions.
- `pandas.DataFrame.describe()` can give you descriptive statistics.
- Use `seaborn.pairplot()` or `pandas.scatter_matrix()` to visualize possible correlations.

</details>

### Task 3: Data Cleaning
- Handle missing values and remove or impute where appropriate.
- Convert categorical data to numerical data using one-hot encoding or label encoding.
- Merge if appropriate.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Check for missing values using `pandas.DataFrame.isnull().sum()`.
- Consider using `pandas.DataFrame.dropna()` to remove rows with missing values or `pandas.DataFrame.fillna()` to impute them.
- For encoding categorical variables, look into `pandas.get_dummies()` for one-hot encoding or `sklearn.preprocessing.LabelEncoder` for label encoding.

</details>

## Part 2: Feature Engineering and Selection

In this section, you will perform date preparation and exploration on your chosen dataset. You will retrieve and load the data, clean the data, and perform a concise exploratory data analysis.

### Task 1: Feature Engineering
- Create new features if necessary from existing data.
- Normalize or standardize features if needed.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Think about what additional information might be useful that's not directly provided in the features.
- Standardize features with `sklearn.preprocessing.StandardScaler` or normalize them with `sklearn.preprocessing.MinMaxScaler`.

</details>

### Task 2: Feature Selection
- Use statistical tests, selection methods, or model-based methods to select a subset of features for the classification.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Use methods like `SelectKBest` from `sklearn.feature_selection` to select features based on univariate statistical tests.
- Consider using `feature_importances_` from tree-based models like RandomForest to evaluate feature importance.
- Consider removing correlated pairs like we did in class

</details>

## Part 3: Model Implementation

This section will focus on cleaning and preparing the dataset for modeling. You will correct any issues you found during the EDA phase.

### Task 1: Data Splitting
- Split the dataset into a training set and a test set.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Use `sklearn.model_selection.train_test_split` to separate your data into training and testing sets.
- Consider using PCA for dimensional reduction, picking the optimal components like we did in class.

</details>

### Task 2: Model Training
- Train at least three of the following classification models:
  - Logistic Regression (3 points)
  - Decision Tree Classifier (3 points)
  - Random Forest Classifier (3 points)
  - K-Nearest Neighbors (3 points)
- For each model, briefly explain the working principle.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- For each algorithm, ensure you understand the basic principle; logistic regression is about probabilities, decision trees make hierarchical decisions, etc.
- Consult the scikit-learn documentation for details on parameters and usage of different classifiers.

</details>

### Task 3: Model Validation
- Use cross-validation to estimate the effectiveness of each model.
- Report the accuracy, precision, recall, F1-score, and ROC-AUC for each model.

<details>
  <summary><h3><b>Hint</b></h3></summary>

- Implement cross-validation using `sklearn.model_selection.cross_val_score` or `sklearn.model_selection.cross_validate`.
- For metrics, explore `sklearn.metrics` for functions like `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, and `roc_auc_score`.

</details>

## Part 4: Model Evaluation and Interpretation

### Task 1: Model Comparison + Result Interpretation
- Interpret the results of the best performing model.
- Discuss the importance of feature contributions to the model's predictions.
- Reflect on the potential real-world implications of the model's performance (e.g., overfitting, misclassification costs).

<details>
  <summary><h3><b>Hint</b></h3></summary>

- When interpreting the ROC curve, recall that a curve closer to the top-left corner indicates a better performance.

</details>

---

**Deliverables:**
- A Quarto Notebook containing all code and visualizations.
- A written report summarizing your findings from the EDA, the decisions you made during preprocessing, and the rationale behind your choices.

**Submission Guidelines:**
- Push your Quarto Notebook to your GitHub repository.
- Ensure your commit messages are descriptive.

**Grading Rubric:**
Your work will be evaluated based on the following criteria:
- Correctness and completeness of the code.
- Quality and clarity of the visualizations and summary report.
- Proper use of comments and documentation in the code.
- Adherence to the submission guidelines.

**Points Distribution:**
Each task is allocated a specific number of points. Points will be awarded based on the completeness and correctness of the work submitted. Be sure to follow best practices in data analysis and provide interpretations for your findings and decisions during preprocessing.

Good luck, and may your insights be profound!