[
  {
    "objectID": "presentation.html#introduction",
    "href": "presentation.html#introduction",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Introduction",
    "text": "Introduction\nSince its inception in the late 16th century, cricket has established itself as once of the most popular sports on the planet with yearly viewers numbering in the billions. With so many viewers, prediction of match outcomes have become a hot topic for enthusiasts and sports bettors alike. We plan to use “live” data from 2023 to predict the outcome of the match based on a logistic regression model that takes into account features that are dynamically changing. With each match “update” we will feed the new data into our model to update the prediction it is making. By doing so we can dynamically see how the outcome of a game changes as the match progresses."
  },
  {
    "objectID": "presentation.html#layouts",
    "href": "presentation.html#layouts",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Layouts",
    "text": "Layouts\nYou can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\n\nlike\nthis\n\nAnd add footnotes"
  },
  {
    "objectID": "presentation.html#code",
    "href": "presentation.html#code",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Code",
    "text": "Code\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.073\nModel:                            OLS   Adj. R-squared:                  0.070\nMethod:                 Least Squares   F-statistic:                     30.59\nDate:                Fri, 03 May 2024   Prob (F-statistic):           5.84e-08\nTime:                        19:03:44   Log-Likelihood:                -1346.4\nNo. Observations:                 392   AIC:                             2697.\nDf Residuals:                     390   BIC:                             2705.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         35.8015      2.266     15.800      0.000      31.347      40.257\nspeed       -354.7055     64.129     -5.531      0.000    -480.788    -228.623\n==============================================================================\nOmnibus:                       27.687   Durbin-Watson:                   0.589\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               18.976\nSkew:                           0.420   Prob(JB):                     7.57e-05\nKurtosis:                       2.323   Cond. No.                         169.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "presentation.html#plots",
    "href": "presentation.html#plots",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Plots",
    "text": "Plots"
  },
  {
    "objectID": "presentation.html#plot-and-text",
    "href": "presentation.html#plot-and-text",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Plot and text",
    "text": "Plot and text\n\n\n\nSome text\ngoes here"
  },
  {
    "objectID": "presentation.html#tables",
    "href": "presentation.html#tables",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Tables",
    "text": "Tables\nIf you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\n\n\n\nisland\n\n\n\nbill_length_mm\n\n\n\nbill_depth_mm\n\n\n\nflipper_length_mm\n\n\n\nbody_mass_g\n\n\n\nsex\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.1\n\n\n\n18.7\n\n\n\n181.0\n\n\n\n3750.0\n\n\n\nMale\n\n\n\n\n\n\n\n1\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.5\n\n\n\n17.4\n\n\n\n186.0\n\n\n\n3800.0\n\n\n\nFemale\n\n\n\n\n\n\n\n2\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n40.3\n\n\n\n18.0\n\n\n\n195.0\n\n\n\n3250.0\n\n\n\nFemale\n\n\n\n\n\n\n\n4\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n36.7\n\n\n\n19.3\n\n\n\n193.0\n\n\n\n3450.0\n\n\n\nFemale\n\n\n\n\n\n\n\n5\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.3\n\n\n\n20.6\n\n\n\n190.0\n\n\n\n3650.0\n\n\n\nMale"
  },
  {
    "objectID": "presentation.html#images",
    "href": "presentation.html#images",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Images",
    "text": "Images\n\nImage credit: Danielle Navarro, Percolate."
  },
  {
    "objectID": "presentation.html#math-expressions",
    "href": "presentation.html#math-expressions",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Math Expressions",
    "text": "Math Expressions\nYou can write LaTeX math expressions inside a pair of dollar signs, e.g. $\\alpha+\\beta$ renders \\(\\alpha + \\beta\\). You can use the display style with double dollar signs:\n$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n\\[\n\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\n\\]\nLimitations:\n\nThe source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character;\nThere should not be spaces after the opening $ or before the closing $."
  },
  {
    "objectID": "presentation.html#feeling-adventurous",
    "href": "presentation.html#feeling-adventurous",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Feeling adventurous?",
    "text": "Feeling adventurous?\n\nYou are welcomed to use the default styling of the slides. In fact, that’s what I expect majority of you will do. You will differentiate yourself with the content of your presentation.\nBut some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "",
    "text": "Our project predicts the match results by using historical ODI cricket data and state-of-the-art machine learning. It redefines cricket analysis by closely monitoring forecast accuracy and encouraging user engagement. The primary goal of our project is to use historical and current match data, train them under regression classification models, select the best model and then use it to predict the winner of a cricket match based on the live match statistics (e.g., runs scored, wickets fallen, overs bowled), that update at regular intervals. This model will be displayed on a webpage which will refresh every time a new stat is updated, and the prediction from the model will update."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "",
    "text": "Our project predicts the match results by using historical ODI cricket data and state-of-the-art machine learning. It redefines cricket analysis by closely monitoring forecast accuracy and encouraging user engagement. The primary goal of our project is to use historical and current match data, train them under regression classification models, select the best model and then use it to predict the winner of a cricket match based on the live match statistics (e.g., runs scored, wickets fallen, overs bowled), that update at regular intervals. This model will be displayed on a webpage which will refresh every time a new stat is updated, and the prediction from the model will update."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Introduction",
    "text": "Introduction\nFor this project we wanted to showcase our prediction skill-set with the challenge of a live dataset, and what better live dataset to use than sports, so we went with our favorite sport - cricket. The past data will include information of ODI Matches from years 2002 to 2022, while the live data will consist of data from the year 2023. Each entry from 2023 will be read from the actual CSV file and entered into a database table with an interval of 10 to 20 seconds between two consecutive entries. These entries will be considered as live data and will be sent to the API caller.\nWe’ll use two datasets:\nODI_Match_Data.csv: Provides facts about the location and season of the cricket matches along with team information and the play results from each team member. We’ll need this one to investigate partnerships between batsmen. It’s dimensions are 155432 rows of data by 23 variable columns. The data that appears in this proposal is a truncated version for ease of storage, but the project will utilize an API that will supply the entire dataset.\nODI_Match_info.csv: Overlaps in data with the above but provides information on the umpire, performance, and the city the match took place. We’ll need this one to analyze the batting and bowling performance of each player. It’s dimensions are 2380 rows of data by 18 variable columns."
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport glob\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier  \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport pickle"
  },
  {
    "objectID": "index.html#eda",
    "href": "index.html#eda",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "EDA",
    "text": "EDA\nHere, we first carried out Data Preprocessing where we merged the match_data and match_info files, then carried out Exploratory Data Analysis by using pairplots to find correlations between different variables, if any.\n\ninfo = pd.read_csv('data/ODI_Match_info.csv')\ninfo = info.rename(columns = {'id':'match_id'})\n\n#append all files together\ncsv_files = ['data/output_1.csv','data/output_2.csv','data/output_3.csv','data/output_4.csv','data/output_5.csv','data/output_6.csv','data/output_7.csv','data/output_8.csv','data/output_9.csv']\n\nmatchData = pd.concat([pd.read_csv(f,low_memory=False) for f in csv_files ], ignore_index=True)\n\n#merge frames on match ID column\n\ntotalData = pd.merge(matchData, info, on = 'match_id') #merge by identical column 'match_id'\ntotalData.drop(totalData.filter(regex='_y$').columns, axis=1, inplace=True) #drop duplicate columns\n\ntotalData = totalData.rename(columns = {'season_x':'season', 'venue_x':'venue'})\n\nfrom02to22 = totalData[~totalData['season'].astype(str).str.startswith(('2023/2024','2023', '2022/23'))] #exclude 2023 data\n\nfrom02to22\nprint(type(from02to22)) #confirm data is read in as a df\nprint(from02to22.shape) #confirm data shape\nprint(from02to22.dtypes) #understand the types of data in the df\nprint(from02to22.isna().sum()) #count NA values in columns\nprint(pd.DataFrame.describe(from02to22)) #descriptive function to look at dataframe)\n\n\nwinners = sns.countplot(data = from02to22, y = 'winner', order=from02to22['winner'].value_counts().index)\nwinners\n\n# corr = sns.pairplot(from02to22)\n# corr\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\n(1170917, 38)\nmatch_id                    int64\nseason                     object\nstart_date                 object\nvenue                      object\ninnings                     int64\nball                      float64\nbatting_team               object\nbowling_team               object\nstriker                    object\nnon_striker                object\nbowler                     object\nruns_off_bat                int64\nextras                      int64\nwides                     float64\nnoballs                   float64\nbyes                      float64\nlegbyes                   float64\npenalty                   float64\nwicket_type                object\nplayer_dismissed           object\nother_wicket_type         float64\nother_player_dismissed    float64\ncricsheet_id                int64\ncity                       object\ndate                       object\nteam1                      object\nteam2                      object\ntoss_winner                object\ntoss_decision              object\nresult                     object\ndl_applied                  int64\nwinner                     object\nwin_by_runs                 int64\nwin_by_wickets              int64\nplayer_of_match            object\numpire1                    object\numpire2                    object\numpire3                    object\ndtype: object\nmatch_id                        0\nseason                          0\nstart_date                      0\nvenue                           0\ninnings                         0\nball                            0\nbatting_team                    0\nbowling_team                    0\nstriker                         0\nnon_striker                     0\nbowler                          0\nruns_off_bat                    0\nextras                          0\nwides                     1144180\nnoballs                   1166089\nbyes                      1169151\nlegbyes                   1158834\npenalty                   1170904\nwicket_type               1139201\nplayer_dismissed          1139201\nother_wicket_type         1170917\nother_player_dismissed    1170917\ncricsheet_id                    0\ncity                       164797\ndate                            0\nteam1                           0\nteam2                           0\ntoss_winner                     0\ntoss_decision                   0\nresult                          0\ndl_applied                      0\nwinner                      31969\nwin_by_runs                     0\nwin_by_wickets                  0\nplayer_of_match             47608\numpire1                         0\numpire2                         0\numpire3                    126959\ndtype: int64\n           match_id       innings          ball  runs_off_bat        extras  \\\ncount  1.170917e+06  1.170917e+06  1.170917e+06  1.170917e+06  1.170917e+06   \nmean   6.599334e+05  1.457323e+00  2.268423e+01  7.865784e-01  4.903934e-02   \nstd    4.018850e+05  4.982441e-01  1.382769e+01  1.249957e+00  2.941420e-01   \nmin    6.481400e+04  1.000000e+00  1.000000e-01  0.000000e+00  0.000000e+00   \n25%    2.990100e+05  1.000000e+00  1.060000e+01  0.000000e+00  0.000000e+00   \n50%    5.730140e+05  1.000000e+00  2.210000e+01  0.000000e+00  0.000000e+00   \n75%    1.104478e+06  2.000000e+00  3.420000e+01  1.000000e+00  0.000000e+00   \nmax    1.331370e+06  4.000000e+00  4.990000e+01  7.000000e+00  6.000000e+00   \n\n              wides      noballs         byes       legbyes  penalty  \\\ncount  26737.000000  4828.000000  1766.000000  12083.000000     13.0   \nmean       1.202304     1.038318     2.063420      1.369941      5.0   \nstd        0.789166     0.328190     1.314314      0.884506      0.0   \nmin        1.000000     1.000000     1.000000      1.000000      5.0   \n25%        1.000000     1.000000     1.000000      1.000000      5.0   \n50%        1.000000     1.000000     1.000000      1.000000      5.0   \n75%        1.000000     1.000000     4.000000      1.000000      5.0   \nmax        5.000000     5.000000     4.000000      5.000000      5.0   \n\n       other_wicket_type  other_player_dismissed  cricsheet_id    dl_applied  \\\ncount                0.0                     0.0  1.170917e+06  1.170917e+06   \nmean                 NaN                     NaN  6.599334e+05  7.751531e-02   \nstd                  NaN                     NaN  4.018850e+05  2.674075e-01   \nmin                  NaN                     NaN  6.481400e+04  0.000000e+00   \n25%                  NaN                     NaN  2.990100e+05  0.000000e+00   \n50%                  NaN                     NaN  5.730140e+05  0.000000e+00   \n75%                  NaN                     NaN  1.104478e+06  0.000000e+00   \nmax                  NaN                     NaN  1.331370e+06  1.000000e+00   \n\n        win_by_runs  win_by_wickets  \ncount  1.170917e+06    1.170917e+06  \nmean   3.503768e+01    2.651942e+00  \nstd    5.257946e+01    3.139602e+00  \nmin    0.000000e+00    0.000000e+00  \n25%    0.000000e+00    0.000000e+00  \n50%    0.000000e+00    0.000000e+00  \n75%    5.900000e+01    6.000000e+00  \nmax    2.750000e+02    1.000000e+01"
  },
  {
    "objectID": "index.html#data-cleaning",
    "href": "index.html#data-cleaning",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nHere, during a thorough process of Data Cleaning, we dropped some columns which were largely empty and replaced some empties with ‘Unknown’.\n\n#drop columns that have more than 1Million NaNs\n\ncolNaCounts = from02to22.isna().sum()\n\n\ncolumns_to_drop = colNaCounts[colNaCounts &gt;= 1000000].index.tolist()\n\n# Drop identified columns from the DataFrame\nfrom02to22 = from02to22.drop(columns=columns_to_drop)\n\n\n#revalue new winner column\n\nfrom02to22['winnerTeam'] = from02to22.apply(lambda row: 'team1' if row['winner'] == row['team1'] else 'team2', axis=1)\n\nfrom02to22['toss_winner'] = from02to22.apply(lambda row: 'team1' if row['toss_winner'] == row['team1'] else 'team2', axis=1)\n\n\n\n#convert Nan cities to 'Unknown'\n#drop winner NA columns\n#convert NA player of match to 'unknown'\n#convert NA umpire 3 to 'unknown'\n\nfrom02to22['city'] = from02to22['city'].fillna('Unknown') \nfrom02to22['player_of_match'] = from02to22['player_of_match'].fillna('Unknown') \nfrom02to22['umpire3'] = from02to22['umpire3'].fillna('Unknown') \nfrom02to22 = from02to22.dropna(subset=['winner'])\nfrom02to22 = from02to22.drop(columns = ['match_id', 'start_date', 'date', 'winner', 'cricsheet_id', 'season', 'venue', 'city', 'player_of_match', 'win_by_runs', 'win_by_wickets', 'umpire1', 'umpire2', 'umpire3', 'result']) #is date specific data really useful? also drop continuous match identifiers. We want the match stats\n# corr = sns.pairplot(from02to22)\n# corr"
  },
  {
    "objectID": "index.html#updated-feature-engineering",
    "href": "index.html#updated-feature-engineering",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Updated feature engineering",
    "text": "Updated feature engineering\n\nimport joblib\n\nto_norm = (from02to22.select_dtypes(include =['int64', 'float64']))\nto_encode = (from02to22.select_dtypes(include =['object']))\n\ncricDataSet = from02to22.copy()\n\nlabel_encoder = LabelEncoder()\nmin_max_scaler = MinMaxScaler()\n\nlabel_encoders = {}\n\nfor col in cricDataSet.columns:\n    if cricDataSet[col].dtype == 'object':  # Check if column is categorical\n        label_encoders[col] = LabelEncoder()\n        label_encoders[col].fit(cricDataSet[col])\n        cricDataSet[col] = label_encoders[col].transform(cricDataSet[col])\n\n# Save label encoder and scaler objects to disk\nfor col, encoder in label_encoders.items():\n    joblib.dump(encoder, f'data/label_encoder_{col}.joblib')\n\ncricDataSet[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']] = min_max_scaler.fit_transform(cricDataSet[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']])\n\n# # Save label encoder and scaler objects to disk\n# with open(\"data/label_encoder.pkl\", \"wb\") as f:\n#     pickle.dump(label_encoder, f)\n\n# with open(\"data/min_max_scaler.pkl\", \"wb\") as f:\n#     pickle.dump(min_max_scaler, f)\n\njoblib.dump(label_encoder, 'data/label_encoder.joblib')\njoblib.dump(min_max_scaler, 'data/min_max_scaler.joblib')\n\nfrom02to22.head()\n\n\n\n\n\n\n\n\ninnings\nball\nbatting_team\nbowling_team\nstriker\nnon_striker\nbowler\nruns_off_bat\nextras\nteam1\nteam2\ntoss_winner\ntoss_decision\ndl_applied\nwinnerTeam\n\n\n\n\n94186\n1\n0.1\nNamibia\nPapua New Guinea\nL Louwrens\nD la Cock\nN Pokana\n4\n0\nNamibia\nPapua New Guinea\nteam1\nbat\n0\nteam1\n\n\n94187\n1\n0.2\nNamibia\nPapua New Guinea\nL Louwrens\nD la Cock\nN Pokana\n0\n1\nNamibia\nPapua New Guinea\nteam1\nbat\n0\nteam1\n\n\n94188\n1\n0.3\nNamibia\nPapua New Guinea\nL Louwrens\nD la Cock\nN Pokana\n0\n0\nNamibia\nPapua New Guinea\nteam1\nbat\n0\nteam1\n\n\n94189\n1\n0.4\nNamibia\nPapua New Guinea\nL Louwrens\nD la Cock\nN Pokana\n0\n0\nNamibia\nPapua New Guinea\nteam1\nbat\n0\nteam1\n\n\n94190\n1\n0.5\nNamibia\nPapua New Guinea\nL Louwrens\nD la Cock\nN Pokana\n0\n0\nNamibia\nPapua New Guinea\nteam1\nbat\n0\nteam1\n\n\n\n\n\n\n\n\ncricDataSet\n\n\n\n\n\n\n\n\ninnings\nball\nbatting_team\nbowling_team\nstriker\nnon_striker\nbowler\nruns_off_bat\nextras\nteam1\nteam2\ntoss_winner\ntoss_decision\ndl_applied\nwinnerTeam\n\n\n\n\n94186\n0.0\n0.000000\n13\n19\n819\n339\n810\n0.571429\n0.000000\n11\n18\n0\n0\n0.0\n0\n\n\n94187\n0.0\n0.002008\n13\n19\n819\n339\n810\n0.000000\n0.166667\n11\n18\n0\n0\n0.0\n0\n\n\n94188\n0.0\n0.004016\n13\n19\n819\n339\n810\n0.000000\n0.000000\n11\n18\n0\n0\n0.0\n0\n\n\n94189\n0.0\n0.006024\n13\n19\n819\n339\n810\n0.000000\n0.000000\n11\n18\n0\n0\n0.0\n0\n\n\n94190\n0.0\n0.008032\n13\n19\n819\n339\n810\n0.000000\n0.000000\n11\n18\n0\n0\n0.0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1265098\n1.0\n0.853414\n10\n16\n622\n1600\n867\n0.000000\n0.000000\n14\n9\n1\n1\n0.0\n0\n\n\n1265099\n1.0\n0.863454\n10\n16\n1611\n618\n583\n0.142857\n0.000000\n14\n9\n1\n1\n0.0\n0\n\n\n1265100\n1.0\n0.865462\n10\n16\n622\n1600\n583\n0.000000\n0.000000\n14\n9\n1\n1\n0.0\n0\n\n\n1265101\n1.0\n0.867470\n10\n16\n1611\n15\n583\n0.285714\n0.000000\n14\n9\n1\n1\n0.0\n0\n\n\n1265102\n1.0\n0.869478\n10\n16\n1611\n15\n583\n0.000000\n0.000000\n14\n9\n1\n1\n0.0\n0\n\n\n\n\n1138948 rows × 15 columns"
  },
  {
    "objectID": "index.html#feature-engineering",
    "href": "index.html#feature-engineering",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nThe next step is the Feature Engineering where we: - Normalized the continuous data - Encoded categorical variables\n\n#normalize continuous data because we dont have a normal distribution\n\nto_norm = (from02to22.select_dtypes(include =['int64', 'float64'])) #select continuous variables\n\ncontinuous = MinMaxScaler().fit_transform(to_norm) #fit and transform min max scaler (normalizes)\ncontinuous = pd.DataFrame(continuous, index = from02to22.index, columns = list(to_norm))\n\n#encode categorical variables\n\nto_encode = (from02to22.select_dtypes(include =['object'])) #test if anything is an object or category variable\n\nlabel_encoders = [] #make new encoder for each column\nencoded_data = pd.DataFrame()\n\nencoding_dicts = {}\n\n# Iterate over each column in 'to_encode' and encode using a separate LabelEncoder\nfor col in to_encode:\n    # Create a new instance of LabelEncoder for the current column\n    encoder = LabelEncoder()\n    \n    # Fit and transform the data in 'from02to22[col]'\n    encoded_data[col] = encoder.fit_transform(from02to22[col])\n    \n    # Store the encoder in the list\n    label_encoders.append(encoder)\n\n    encoding_dicts[col] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n\n\n#patch the columns back together\n\ndata = pd.concat([encoded_data.reset_index(drop=True), continuous.reset_index(drop=True)], axis = 1) #reset indices to avoid errors in concat"
  },
  {
    "objectID": "index.html#feature-selection",
    "href": "index.html#feature-selection",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Feature Selection",
    "text": "Feature Selection\nAs we have eliminated the unnecessary columns from data previously through data preprocessing and cleaning, now we directly select the top 10 columns except winnerTeam as the input features of the model and the winnerTeam itself as the target feature.\n\nX = cricDataSet.drop('winnerTeam', axis = 1) #input\ny = cricDataSet['winnerTeam'] #target\n\nselector = SelectKBest(score_func= f_classif, k = 10)\ntop10 = selector.fit_transform(X,y) #create variable that is the top 10 best feautures\ncols_idxs = selector.get_support(indices=True) #grab indices from feature cols, get_support is from **sklearn**\ntop10 = X.iloc[:,cols_idxs] #add columns from whole dataset to the selected columns dataset https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le\ntop10.head()\n\n\n\n\n\n\n\n\nball\nbatting_team\nbowling_team\nnon_striker\nbowler\nruns_off_bat\nteam1\nteam2\ntoss_winner\ndl_applied\n\n\n\n\n94186\n0.000000\n13\n19\n339\n810\n0.571429\n11\n18\n0\n0.0\n\n\n94187\n0.002008\n13\n19\n339\n810\n0.000000\n11\n18\n0\n0.0\n\n\n94188\n0.004016\n13\n19\n339\n810\n0.000000\n11\n18\n0\n0.0\n\n\n94189\n0.006024\n13\n19\n339\n810\n0.000000\n11\n18\n0\n0.0\n\n\n94190\n0.008032\n13\n19\n339\n810\n0.000000\n11\n18\n0\n0.0\n\n\n\n\n\n\n\n\nX.columns\n\nIndex(['innings', 'ball', 'batting_team', 'bowling_team', 'striker',\n       'non_striker', 'bowler', 'runs_off_bat', 'extras', 'team1', 'team2',\n       'toss_winner', 'toss_decision', 'dl_applied'],\n      dtype='object')"
  },
  {
    "objectID": "index.html#model-training-logistic-regression",
    "href": "index.html#model-training-logistic-regression",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Model Training (Logistic Regression)",
    "text": "Model Training (Logistic Regression)\nThe input features and target feature are now broken down into training and testing groups and are put under our first regression model - Logistic regression.\n\n#split data into training and testing\n\n\n#break into 4 groups for testing and training, make the training dataset 70% of the data and the testing dataset 30% https://builtin.com/data-science/train-test-split\n# X_train, X_test, y_train, y_test = tts(top10, y, test_size = 0.2) \n\n\nX_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2) \n\n#PCA\n# pca = PCA(n_components = 5) #go from 10 components to 5 components\n# X_train_pca = pca.fit_transform(X_train)\n# X_test_pca = pca.transform(X_test)\n\n# X_train = X_train_pca\n# X_test = X_test_pca\n\n#training and testing models\n\n #decision tree\n# lr = LogisticRegression()\n\n# lr.fit(X_train, \n#           y_train)\n# predictLR = lr.predict(X_test)\n# outcomeLR = pd.DataFrame ({'Actual': y_test, 'Predicted': predictLR})\n# outcomeLR['Actual'] = label_encoders[9].inverse_transform(outcomeLR['Actual'])\n# outcomeLR['Predicted'] = label_encoders[9].inverse_transform(outcomeLR['Predicted'])\n\n# key = (label_encoders[9].classes_)"
  },
  {
    "objectID": "index.html#model-validation",
    "href": "index.html#model-validation",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Model Validation",
    "text": "Model Validation\nThe results of Logistic regression are now cross validated and their performance metrics are displayed. As we observe the accuracy and precision of this model is around 55% and the area under ROC curve is also around 0.5. As these metrics show that this might not be the best model, we move forward and train another model.\n\n# #Evaluating models\n# #logistic regression\n# cvLR = cross_validate(lr,X_train, y_train)\n# print(\"cross validation of logistic regression\", cvLR)\n# print(\"accuracy of logistic regression:\", metrics.accuracy_score(y_test, predictLR)) #testing how accuracy of the models\n# print(\"precision of logistic regression:\", metrics.precision_score(y_test, predictLR, average = 'weighted'))\n# print(\"recall of logistic regression:\", metrics.recall_score(y_test, predictLR, average = 'weighted'))\n# print(\"f1 of logistic regression:\", metrics.f1_score(y_test, predictLR, average = 'weighted'))\n# print(\"ROCAUC macro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR))\n# print(\"ROCAUC micro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR, average = 'micro'))\n\n\n# y_pred_proba = lr.predict_proba(X_test)[::,1] #https://www.statology.org/plot-roc-curve-python/\n# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n# plt.plot(fpr,tpr)\n# plt.ylabel('True Positive Rate')\n# plt.xlabel('False Positive Rate')\n# plt.title('ROC Curve Logistic Regression')\n# plt.show()\n\n# print('')\n\n\nRandom Forest Classifier\nNow we take the Random Forest Classifier, cross validate its results and display its performance metrics. As we observe the accuracy and precision of this model is around 96% and the area under ROC curve is also around 0.96. These metrics clearly show that this is the best model, so we move forward with this model.\n\n#random forest\nrfc = RandomForestClassifier(criterion='gini')\nrfc.fit(X_train, \n          y_train)\n# # predictRFC = rfc.predict(X_test)\n# # outcomeRFC = pd.DataFrame ({'Actual': y_test, 'Predicted': predictRFC})\n# # outcomeRFC['Actual'] = label_encoders[9].inverse_transform(outcomeRFC['Actual'])\n# # outcomeRFC['Predicted'] = label_encoders[9].inverse_transform(outcomeRFC['Predicted'])\n\n# #Evaluating models\n# #random forest\n# cvRF = cross_validate(rfc,X_train, y_train)\n# print(\"cross validation of random forest\", cvRF)\n# print(\"accuracy of random forest:\", metrics.accuracy_score(y_test, predictRFC)) #testing how accuracy of the models\n# print(\"precision of random forest:\", metrics.precision_score(y_test, predictRFC, average = 'weighted'))\n# print(\"recall of random forest:\", metrics.recall_score(y_test, predictRFC, average = 'weighted'))\n# print(\"f1 of random forest:\", metrics.f1_score(y_test, predictRFC, average = 'weighted'))\n# print(\"ROCAUC macro of random forest:\", metrics.roc_auc_score(y_test, predictRFC))\n# print(\"ROCAUC micro of random forest:\", metrics.roc_auc_score(y_test, predictRFC, average = 'micro'))\n\n\n# y_pred_proba = rfc.predict_proba(X_test)[::,1]\n# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n# plt.plot(fpr,tpr)\n# plt.ylabel('True Positive Rate')\n# plt.xlabel('False Positive Rate')\n# plt.title('ROC Curve Random Forest')\n# plt.show()\n\n#FOR LOCAL USE\n# Step 2: Save the trained model to a pickle file\n# with open(\"/Users/cortmann/Desktop/523 - Data Mining/localCricketPredictions/cricketPrediction.pkl\", \"wb\") as f:\n#     pickle.dump(rfc, f)\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier() \n\n\n\nfrom sklearn.metrics import accuracy_score\nyPred = rfc.predict(X_test)\n\n\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, yPred)\nprint(\"Accuracy:\", accuracy * 100, \"%\")\n\nAccuracy: 98.96878704069537 %"
  },
  {
    "objectID": "index.html#feed-2023-data",
    "href": "index.html#feed-2023-data",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Feed 2023 Data",
    "text": "Feed 2023 Data\nNow we feed the live data (which is the 2023 match data), through back end API, at regular intervals, thereby changing the stats everytime. And each time a statistic is updated, the prediction updates as well.\n\n# Step 2: Save the trained model to a pickle file\nwith open(\"data/cricketPrediction.pkl\", \"wb\") as f:\n    pickle.dump(rfc, f)\n    \n\n\n# Step 3: Load the model from the pickle file\n\n# with open(\"linear_regression_model.pkl\", \"rb\") as f:\n#     loaded_model = pickle.load(f)"
  },
  {
    "objectID": "index.html#model-implementation",
    "href": "index.html#model-implementation",
    "title": "‘2023’ Live Cricket Match Winner Predictions",
    "section": "Model Implementation",
    "text": "Model Implementation\nFinally, we display the model predictionm on a webpage and take you through our journey of prediction!\n\nloaded_model = None\n\n# Load the model from the pickle file\nwith open(\"data/cricketPrediction.pkl\", \"rb\") as f:\n    loaded_model = pickle.load(f)\n    \npredictRFC = loaded_model.predict(X_test)\n\noutcomeRFC = pd.DataFrame ({'Actual': y_test, 'Predicted': predictRFC})\noutcomeRFC['Actual'] = label_encoders[9].inverse_transform(outcomeRFC['Actual'])\noutcomeRFC['Predicted'] = label_encoders[9].inverse_transform(outcomeRFC['Predicted'])\n    \n\n\n# cvRF = cross_validate(loaded_model,X_train, y_train)\n# print(\"cross validation of random forest\", cvRF)\n# print(\"accuracy of random forest:\", metrics.accuracy_score(y_test, predictRFC)) #testing how accuracy of the models\n# print(\"precision of random forest:\", metrics.precision_score(y_test, predictRFC, average = 'weighted'))\n# print(\"recall of random forest:\", metrics.recall_score(y_test, predictRFC, average = 'weighted'))\n# print(\"f1 of random forest:\", metrics.f1_score(y_test, predictRFC, average = 'weighted'))\n# print(\"ROCAUC macro of random forest:\", metrics.roc_auc_score(y_test, predictRFC))\n# print(\"ROCAUC micro of random forest:\", metrics.roc_auc_score(y_test, predictRFC, average = 'micro'))\n\n\n# y_pred_proba = loaded_model.predict_proba(X_test)[::,1]\n# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n# plt.plot(fpr,tpr)\n# plt.ylabel('True Positive Rate')\n# plt.xlabel('False Positive Rate')\n# plt.title('ROC Curve Random Forest')\n# plt.show()\n\n\nimport json\n\nteams = pd.concat([from02to22['team1'], from02to22['team2']]).unique()\n\n# Create a dictionary mapping each team to a unique number\nteam_map = {team: i+1 for i, team in enumerate(teams)}\n\nplayers = pd.concat([from02to22['striker'], from02to22['non_striker'], from02to22['bowler']]).unique()\n\nplayer_map = {player: i+1 for i, player in enumerate(players)}\n\nwith open('data/team_map.json', 'w') as f:\n    json.dump(team_map, f)\n\nwith open('data/player_map.json', 'w') as f:\n    json.dump(player_map, f)\n\n\n# Load the team map dictionary from the saved JSON file\nwith open('data/team_map.json', 'r') as f:\n    team_map_loaded = json.load(f)\n\nwith open('data/player_map.json', 'r') as f:\n    player_map_loaded = json.load(f)\n\ntemp = from02to22.copy()\n\nteam_map_loaded = dict(team_map_loaded)\nplayer_map_loaded = dict(player_map_loaded)\n\ntemp['team1'] = temp['team1'].apply(lambda x: team_map_loaded.get(x))\n\ntemp['team2'] = temp['team2'].apply(lambda x: team_map_loaded.get(x))\n\ntemp['batting_team'] = temp['batting_team'].apply(lambda x: team_map_loaded.get(x))\n\ntemp['bowling_team'] = temp['bowling_team'].apply(lambda x: team_map_loaded.get(x))\n\ntemp['striker'] = temp['striker'].apply(lambda x: player_map_loaded.get(x))\n\ntemp['non_striker'] = temp['non_striker'].apply(lambda x: player_map_loaded.get(x))\n\ntemp['bowler'] = temp['bowler'].apply(lambda x: player_map_loaded.get(x))\n\ntemp['toss_winner'] = temp['toss_winner'].apply(lambda x: 0 if x == \"team1\" else 1)\n\ntemp['winnerTeam'] = temp['winnerTeam'].apply(lambda x: 0 if x == \"team1\" else 1)\n\ntemp['toss_decision'] = temp['toss_decision'].apply(lambda x: 0 if x == \"bat\" else 1)\n\n\nmin_max_scaler = MinMaxScaler()\n\ntemp[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']] = min_max_scaler.fit_transform(temp[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']])\n\njoblib.dump(min_max_scaler, 'data/min_max_scaler.joblib')\n\n['data/min_max_scaler.joblib']\n\n\n\ncricDataSet = temp.copy()\n\nX = cricDataSet.drop('winnerTeam', axis = 1) #input\ny = cricDataSet['winnerTeam'] #target\n\nX_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2) \n\nrfc = RandomForestClassifier(criterion='gini')\nrfc.fit(X_train, \n          y_train)\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier() \n\n\n\nfrom sklearn.metrics import accuracy_score\nyPred = rfc.predict(X_test)\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, yPred)\nprint(\"Accuracy:\", accuracy * 100, \"%\")\n\nAccuracy: 99.04473418499495 %\n\n\n\n# Step 2: Save the trained model to a pickle file\nwith open(\"data/cricketPrediction.pkl\", \"wb\") as f:\n    pickle.dump(rfc, f)\n\n\nimport requests\nimport pandas as pd\n\nloaded_model = None\n\nwith open(\"data/cricketPrediction.pkl\", \"rb\") as f:\n    loaded_model = pickle.load(f)\n\n\n\nmainUrl = \"http://127.0.0.1:8100\"\n\ngetEntireLiveDataApi = \"/analyzingtrends/getentirelivedata\" \ngetCurrentLiveDataApi = \"/analyzingtrends/getcurrentlivedata\"\n\n\n\ndef getAllLiveData():\n  response = requests.get(mainUrl + getEntireLiveDataApi)\n\n  liveData = []\n\n  if response.status_code == 200:  # Check if the request was successful\n      json_data = response.json()  # Convert response to JSON format\n      liveData = pd.DataFrame(json_data)\n  else:\n      print(\"Failed to retrieve data from the API.\")\n\n  return liveData\n\ndef getCurrentLiveData():\n  response = requests.get(mainUrl + getCurrentLiveDataApi)\n  liveList = []\n  liveData = None\n  json_data = None\n\n  if response.status_code == 200:  # Check if the request was successful\n      json_data = response.json()  # Convert response to JSON format\n      liveList.append(json_data)\n      liveData = pd.DataFrame(liveList)\n  else:\n      print(\"Failed to retrieve data from the API.\")\n\n  return liveData, json_data    \n\n\ndef processLiveFeed():\n\n    liveData0, liveJson = getCurrentLiveData()\n    liveData0 = getAllLiveData()\n\n    new_columns = ['match_id', 'season', 'venue', 'innings', 'ball', 'batting_team',\n                'bowling_team', 'striker', 'non_striker', 'bowler', 'runs_off_bat',\n                'extras', 'wides', 'noballs', 'city', 'date', 'team1', 'team2',\n                'toss_winner', 'toss_decision', 'result', 'dl_applied', 'winner',\n                'win_by_runs', 'win_by_wickets', 'player_of_match', 'total_runs', 'id']\n\n    # Rename columns\n    liveData0.columns = new_columns\n    liveData = liveData0.filter(['innings', 'ball', 'batting_team', 'bowling_team', 'striker',\n       'non_striker', 'bowler', 'runs_off_bat', 'extras', 'team1', 'team2',\n       'toss_winner', 'toss_decision', 'dl_applied'])\n\n\n    liveData['toss_winner'] = liveData.apply(lambda row: 'team1' if row['toss_winner'] == row['team1'] else 'team2', axis=1)\n\n\n    # Load the team map dictionary from the saved JSON file\n    with open('data/team_map.json', 'r') as f:\n        team_map_loaded = json.load(f)\n\n    with open('data/player_map.json', 'r') as f:\n        player_map_loaded = json.load(f)\n\n    team_map_loaded = dict(team_map_loaded)\n    player_map_loaded = dict(player_map_loaded)\n\n    liveData['team1'] = liveData['team1'].apply(lambda x: team_map_loaded.get(x))\n\n    liveData['team2'] = liveData['team2'].apply(lambda x: team_map_loaded.get(x))\n\n    liveData['batting_team'] = liveData['batting_team'].apply(lambda x: team_map_loaded.get(x))\n\n    liveData['bowling_team'] = liveData['bowling_team'].apply(lambda x: team_map_loaded.get(x))\n\n    liveData['striker'] = liveData['striker'].apply(lambda x: player_map_loaded.get(x))\n\n    liveData['non_striker'] = liveData['non_striker'].apply(lambda x: player_map_loaded.get(x))\n\n    liveData['bowler'] = liveData['bowler'].apply(lambda x: player_map_loaded.get(x))\n\n    liveData['toss_winner'] = liveData['toss_winner'].apply(lambda x: 0 if x == \"team1\" else 1)\n\n    liveData['toss_decision'] = liveData['toss_decision'].apply(lambda x: 0 if x == \"bat\" else 1)\n\n    loaded_min_max_scaler = joblib.load('data/min_max_scaler.joblib')\n\n    liveData[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']] = loaded_min_max_scaler.transform(liveData[['innings', 'ball', 'runs_off_bat', 'extras', 'dl_applied']])\n\n\n    predictRFC = loaded_model.predict(liveData)\n\n    # Apply mapping function directly to the predicted values (assuming predictRFC is a Series or array)\n    print(predictRFC)\n    out = pd.Series(predictRFC).apply(map_team)\n    out = pd.DataFrame(out)\n    out['match_id'] = liveData0['match_id']\n    print(liveData.head())\n    \n    # countTeamPrediction = Counter(out[0])\n\n    # print(countTeamPrediction)\n\n    return out, liveJson, predictRFC\n\ndef map_team(value):\n    if value == 0:\n        return 'team1'\n    else:\n        return 'team2'\n\n\ndef getPredictionPercent(out):\n    out = dict(out)\n    team1 = out.get(\"team1\")\n    team2 = out.get(\"team2\")\n\n    if(team1 == None):\n        team1 = 0\n\n    if(team2 == None):\n        team2 = 0\n\n    liveData0, liveJson = getCurrentLiveData()\n\n    team1Name = liveJson.get(\"team1\")\n    team2Name = liveJson.get(\"team2\")\n\n    print(team1)\n    print(team2)\n\n    return int(team1), int(team2), team1Name, team2Name\n\n\n# out, liveJson, predictRFC = processLiveFeed()\n\n# team1, team2, team1Name, team2Name = getPredictionPercent(out)\n\n# zeros = np.count_nonzero(predictRFC == 0)\n# total = len(predictRFC)\n# ones = total - zeros\n\n# percTeam1 = (zeros/total) * 100\n# percTeam2 = 100 - percTeam1\n\n# print(percTeam1)\n# print(percTeam2)"
  }
]