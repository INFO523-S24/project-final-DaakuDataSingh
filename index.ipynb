{
  "cells": [
    {
      "cell_type": "raw",
      "id": "97250661",
      "metadata": {},
      "source": [
        "---\n",
        "title: '''2023'' Live Cricket Match Winner Predictions'\n",
        "subtitle: INFO 523 - Project Final\n",
        "author:\n",
        "  - name: Christian Ortmann<br> Pappala Praveen Kumar<br> Poonkundran Srinivasan<br> Srinivasan Akash<br> Theeda Gowtham<br> Tiruthani Rajitha Reddy<br> Bhawari Tejas\n",
        "    affiliations:\n",
        "      - name: 'School of Information, University of Arizona'\n",
        "description: Using Prediction Model to predict Live ODI Cricket Match Winners\n",
        "format:\n",
        "  html:\n",
        "    code-tools: true\n",
        "    code-overflow: wrap\n",
        "    embed-resources: true\n",
        "editor: visual\n",
        "execute:\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-packages",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#| label: load-packages\n",
        "#| include: false\n",
        "\n",
        "# Load packages here\n",
        "# import pandas as pd\n",
        "# import glob\n",
        "# import seaborn as sns\n",
        "# from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "# from sklearn.feature_selection import SelectKBest, f_classif\n",
        "# from sklearn.model_selection import train_test_split as tts\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.tree import DecisionTreeClassifier  \n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn import metrics\n",
        "# from sklearn.model_selection import cross_validate\n",
        "# from sklearn.decomposition import PCA\n",
        "# import matplotlib.pyplot as plt\n",
        "# import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#| label: setup\n",
        "#| include: false\n",
        "# Set up plot theme and figure resolution\n",
        "# sns.set_theme(style=\"whitegrid\")\n",
        "# sns.set_context(\"notebook\", font_scale=1.1)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.rcParams['figure.dpi'] = 300\n",
        "# plt.rcParams['savefig.dpi'] = 300\n",
        "# plt.rcParams['figure.figsize'] = (6, 6 * 0.618)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#| label: load-data\n",
        "#| include: false\n",
        "# # Load data in Python\n",
        "# mtcars = sns.load_dataset('mpg').dropna()  # mtcars dataset is similar to the mpg dataset from seaborn\n",
        "# mtcars['speed'] = mtcars['horsepower'] / mtcars['weight']\n",
        "\n",
        "# penguins = sns.load_dataset('penguins').dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa7a21b",
      "metadata": {},
      "source": [
        "# Introduction {style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "\n",
        "## ODI Cricket\n",
        "\n",
        "Since its inception in the late 16th century, cricket has established itself as once of the most popular sports on the planet with yearly viewers numbering in the billions. With so many viewers, prediction of match outcomes have become a hot topic for enthusiasts and sports bettors alike. We plan to use “live” data from 2023 to predict the outcome of the match based on a logistic regression model that takes into account features that are dynamically changing. With each match “update” we will feed the new data into our model to update the prediction it is making. By doing so we can dynamically see how the outcome of a game changes as the match progresses.\n",
        "\n",
        ":::\n",
        "\n",
        "## Project Goals {style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "In this project we will create a dashboard of a live, ongoing cricket match that updates and predict its plots and statistics at regular intervals.\n",
        "\n",
        ":::\n",
        "## Description of datasets{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "We’ll use two datasets:\n",
        "\n",
        "ODI_Match_Data.csv: Provides facts about the location and season of the cricket matches along with team information and the play results from each team member. We’ll need this one to investigate partnerships between batsmen. It’s dimensions are 155432 rows of data by 23 variable columns. The data that appears in this proposal is a truncated version for ease of storage, but the project will utilize an API that will supply the entire dataset.\n",
        "\n",
        "ODI_Match_info.csv: Overlaps in data with the above but provides information on the umpire, performance, and the city the match took place. We’ll need this one to analyze the batting and bowling performance of each player. It’s dimensions are 2380 rows of data by 18 variable columns.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/download.png)\n",
        ":::\n",
        "## Research goal{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "Match Outcome Prediction -\n",
        "\n",
        "Use historical and current match data with logistic regression classification to predict the winner of a cricket match based on the live match statistics (e.g., runs scored, wickets fallen, overs bowled), that update every minute. Each time a statistic is updated, the prediction will update as well.\n",
        "\n",
        ":::\n",
        "\n",
        "## Mocking Live Data{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "To avoid unnecessary costs associated with real-time data, we will split the data into two parts: past data and live data.\n",
        "\n",
        "The past data will include information from years 2002 to 2022, while the live data will consist of data from the year 2023. Each entry from 2023 will be read from the actual CSV file and entered into a database table with an interval of 10 to 20 seconds between two consecutive entries. These entries will be considered as live data and will be sent to the API caller.\n",
        "\n",
        ":::\n",
        "\n",
        "# Model Building{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "\n",
        "\n",
        "## Exploratory Data Analysis{style=\"font-size: 0.7em;\"}\n",
        "::: incremental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8021278",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# info = pd.read_csv('data/ODI_Match_info.csv')\n",
        "# info = info.rename(columns = {'id':'match_id'})\n",
        "\n",
        "# #append all files together\n",
        "# csv_files = ['data/output_1.csv','data/output_2.csv','data/output_3.csv','data/output_4.csv','data/output_5.csv','data/output_6.csv','data/output_7.csv','data/output_8.csv','data/output_9.csv']\n",
        "\n",
        "# matchData = pd.concat([pd.read_csv(f,low_memory=False) for f in csv_files ], ignore_index=True)\n",
        "\n",
        "# #merge frames on match ID column\n",
        "\n",
        "# totalData = pd.merge(matchData, info, on = 'match_id') #merge by identical column 'match_id'\n",
        "# totalData.drop(totalData.filter(regex='_y$').columns, axis=1, inplace=True) #drop duplicate columns\n",
        "\n",
        "# totalData = totalData.rename(columns = {'season_x':'season', 'venue_x':'venue'})\n",
        "\n",
        "# from02to22 = totalData[~totalData['season'].astype(str).str.startswith(('2023/2024','2023', '2022/23'))] #exclude 2023 data\n",
        "\n",
        "# from02to22\n",
        "# print(type(from02to22)) #confirm data is read in as a df\n",
        "# print(from02to22.shape) #confirm data shape\n",
        "# print(from02to22.dtypes) #understand the types of data in the df\n",
        "# print(from02to22.isna().sum()) #count NA values in columns\n",
        "# print(pd.DataFrame.describe(from02to22)) #descriptive function to look at dataframe)\n",
        "\n",
        "\n",
        "# winners = sns.countplot(data = from02to22, y = 'winner', order=from02to22['winner'].value_counts().index)\n",
        "# winners\n",
        "\n",
        "# # corr = sns.pairplot(from02to22)\n",
        "# # corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7af2b80",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Data Manipulation & Feature Engineering{style=\"font-size: 0.7em;\"}\n",
        "::: incremental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4d1bcd",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# #drop columns that have more than 1Million NaNs\n",
        "\n",
        "# colNaCounts = from02to22.isna().sum()\n",
        "\n",
        "\n",
        "# columns_to_drop = colNaCounts[colNaCounts >= 1000000].index.tolist()\n",
        "\n",
        "# # Drop identified columns from the DataFrame\n",
        "# from02to22 = from02to22.drop(columns=columns_to_drop)\n",
        "\n",
        "\n",
        "# #revalue new winner column\n",
        "\n",
        "# from02to22['winnerTeam'] = from02to22.apply(lambda row: 'team1' if row['winner'] == row['team1'] else 'team2', axis=1)\n",
        "\n",
        "# #convert Nan cities to 'Unknown'\n",
        "# #drop winner NA columns\n",
        "# #convert NA player of match to 'unknown'\n",
        "# #convert NA umpire 3 to 'unknown'\n",
        "\n",
        "# from02to22['city'] = from02to22['city'].fillna('Unknown') \n",
        "# from02to22['player_of_match'] = from02to22['player_of_match'].fillna('Unknown') \n",
        "# from02to22['umpire3'] = from02to22['umpire3'].fillna('Unknown') \n",
        "# from02to22 = from02to22.dropna(subset=['winner'])\n",
        "# from02to22 = from02to22.drop(columns = ['match_id', 'start_date', 'date', 'winner', 'cricsheet_id', 'season', 'venue', 'city', 'player_of_match', 'win_by_runs', 'win_by_wickets', 'umpire1', 'umpire2', 'umpire3', 'result']) #is date specific data really useful? also drop continuous match identifiers. We want the match stats\n",
        "# # corr = sns.pairplot(from02to22)\n",
        "# # corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfea71cb",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a960381f",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# X = data.drop('winnerTeam', axis = 1) #input\n",
        "# y = data['winnerTeam'] #target\n",
        "\n",
        "# selector = SelectKBest(score_func= f_classif, k = 10)\n",
        "# top10 = selector.fit_transform(X,y) #create variable that is the top 10 best feautures\n",
        "# cols_idxs = selector.get_support(indices=True) #grab indices from feature cols, get_support is from **sklearn**\n",
        "# top10 = X.iloc[:,cols_idxs] #add columns from whole dataset to the selected columns dataset https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le\n",
        "# print(top10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bf3adf",
      "metadata": {},
      "source": [
        "## Logistic Regression{style=\"font-size: 0.7em;\"}\n",
        "::: incremental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c4093f",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#split data into training and testing\n",
        "# X_train, X_test, y_train, y_test = tts(top10, y, test_size = 0.2) #break into 4 groups for testing and training, make the training dataset 70% of the data and the testing dataset 30% https://builtin.com/data-science/train-test-split\n",
        "#PCA\n",
        "# pca = PCA(n_components = 5) #go from 10 components to 5 components\n",
        "# X_train_pca = pca.fit_transform(X_train)\n",
        "# X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# X_train = X_train_pca\n",
        "# X_test = X_test_pca\n",
        "\n",
        "#training and testing models\n",
        "\n",
        " #decision tree\n",
        "# lr = LogisticRegression()\n",
        "\n",
        "# lr.fit(X_train, \n",
        "#           y_train)\n",
        "# predictLR = lr.predict(X_test)\n",
        "# outcomeLR = pd.DataFrame ({'Actual': y_test, 'Predicted': predictLR})\n",
        "# outcomeLR['Actual'] = label_encoders[9].inverse_transform(outcomeLR['Actual'])\n",
        "# outcomeLR['Predicted'] = label_encoders[9].inverse_transform(outcomeLR['Predicted'])\n",
        "\n",
        "# key = (label_encoders[9].classes_)\n"
      ]
      ],
      "id": "735d568f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "89951c31",
      "metadata": {},
      "source": [
        "- Pros: Fast training time, easy to implement\n",
        "- Cons:\n",
        "\n",
        ":::\n",
        "\n",
        "## Logistic Regression ROC Curve and Accuracy{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n"
      ]
    },
    {
      "cell_type": "code",
        "## Model Validation\n",
        "The results of Logistic regression are now cross validated and their performance metrics are displayed. As we observe the accuracy and precision of this model is around 55% and the area under ROC curve is also around 0.5. As these metrics show that this might not be the best model, we move forward and train another model."
      ],
      "id": "ad7bb819"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Evaluating models\n",
        "#logistic regression\n",
        "cvLR = cross_validate(lr,X_train, y_train)\n",
        "print(\"cross validation of logistic regression\", cvLR)\n",
        "print(\"accuracy of logistic regression:\", metrics.accuracy_score(y_test, predictLR)) #testing how accuracy of the models\n",
        "print(\"precision of logistic regression:\", metrics.precision_score(y_test, predictLR, average = 'weighted'))\n",
        "print(\"recall of logistic regression:\", metrics.recall_score(y_test, predictLR, average = 'weighted'))\n",
        "print(\"f1 of logistic regression:\", metrics.f1_score(y_test, predictLR, average = 'weighted'))\n",
        "print(\"ROCAUC macro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR))\n",
        "print(\"ROCAUC micro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR, average = 'micro'))\n",
        "\n",
        "\n",
        "y_pred_proba = lr.predict_proba(X_test)[::,1] #https://www.statology.org/plot-roc-curve-python/\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "plt.plot(fpr,tpr)\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.title('ROC Curve Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "print('')\n"
      ],
      "id": "246bb45b",
      "execution_count": null,
      "id": "3d2a7ded",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# #Evaluating models\n",
        "# #logistic regression\n",
        "# cvLR = cross_validate(lr,X_train, y_train)\n",
        "# print(\"cross validation of logistic regression\", cvLR)\n",
        "# print(\"accuracy of logistic regression:\", metrics.accuracy_score(y_test, predictLR)) #testing how accuracy of the models\n",
        "# print(\"precision of logistic regression:\", metrics.precision_score(y_test, predictLR, average = 'weighted'))\n",
        "# print(\"recall of logistic regression:\", metrics.recall_score(y_test, predictLR, average = 'weighted'))\n",
        "# print(\"f1 of logistic regression:\", metrics.f1_score(y_test, predictLR, average = 'weighted'))\n",
        "# print(\"ROCAUC macro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR))\n",
        "# print(\"ROCAUC micro of logistic regression:\", metrics.roc_auc_score(y_test, predictLR, average = 'micro'))\n",
        "\n",
        "\n",
        "# y_pred_proba = lr.predict_proba(X_test)[::,1] #https://www.statology.org/plot-roc-curve-python/\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "# plt.plot(fpr,tpr)\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.title('ROC Curve Logistic Regression')\n",
        "# plt.show()\n",
        "\n",
        "# print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2105e54c",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Random Forest{style=\"font-size: 0.7em;\"}\n",
        "::: incremental"
      ]
        "### Random Forest Classifier\n",
        "Now we take the Random Forest  Classifier, cross validate its results and display its performance metrics. As we observe the accuracy and precision of this model is around 96% and the area under ROC curve is also around 0.96. These metrics clearly show that this is the best model, so we move forward with this model."
      ],
      "id": "aa9e54e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0ea700",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# #random forest\n",
        "# rfc = RandomForestClassifier(criterion='gini')\n",
        "# rfc.fit(X_train, \n",
        "#           y_train)\n",
        "# predictRFC = rfc.predict(X_test)\n",
        "# outcomeRFC = pd.DataFrame ({'Actual': y_test, 'Predicted': predictRFC})\n",
        "# outcomeRFC['Actual'] = label_encoders[9].inverse_transform(outcomeRFC['Actual'])\n",
        "# outcomeRFC['Predicted'] = label_encoders[9].inverse_transform(outcomeRFC['Predicted'])\n",
        "\n",
        "# #Evaluating models\n",
        "# #random forest\n",
        "# cvRF = cross_validate(rfc,X_train, y_train)\n",
        "# print(\"cross validation of random forest\", cvRF)\n",
        "# print(\"accuracy of random forest:\", metrics.accuracy_score(y_test, predictRFC)) #testing how accuracy of the models\n",
        "# print(\"precision of random forest:\", metrics.precision_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"recall of random forest:\", metrics.recall_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"f1 of random forest:\", metrics.f1_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"ROCAUC macro of random forest:\", metrics.roc_auc_score(y_test, predictRFC))\n",
        "# print(\"ROCAUC micro of random forest:\", metrics.roc_auc_score(y_test, predictRFC, average = 'micro'))\n",
        "\n",
        "\n",
        "# y_pred_proba = rfc.predict_proba(X_test)[::,1]\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "# plt.plot(fpr,tpr)\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.title('ROC Curve Random Forest')\n",
        "# plt.show()\n",
        "\n",
        "#FOR LOCAL USE\n",
        "# Step 2: Save the trained model to a pickle file\n",
        "# with open(\"/Users/cortmann/Desktop/523 - Data Mining/localCricketPredictions/cricketPrediction.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(rfc, f)"
      ]
      ],
      "id": "8c92aa11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "48090a2b",
      "metadata": {},
      "source": [
        "- Pros: \n",
        "- Cons: Slow training time\n",
        "\n",
        ":::\n",
        "\n",
        "## Back-End API{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n",
        "GET /current-performance\n",
        "\n",
        "Live Data: Will show the live stats (mocked) of an ongoing match between team A and B\n",
        "\n",
        "Prediction: Who will win out of Team A and B\n",
        "\n",
        "These APIs are subject to change, additions, or removals as we analyze the data.\n",
        ":::\n",
        "\n",
        "\n",
        "# Model Implementation with API{style=\"font-size: 0.7em;\"}\n",
        "::: incremental\n"
      ]
        "## Feed 2023 Data\n",
        "Now we feed the live data (which is the 2023 match data), through back end API, at regular intervals, thereby changing the stats everytime. And each time a statistic is updated, the prediction updates as well."
      ],
      "id": "ad7ffe62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bc1e12d",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Step 2: Save the trained model to a pickle file\n",
        "# with open(\"data/cricketPrediction.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(rfc, f)\n",
        "    \n",
        "\n",
        "\n",
        "# Step 3: Load the model from the pickle file\n",
        "\n",
        "# with open(\"linear_regression_model.pkl\", \"rb\") as f:\n",
        "#     loaded_model = pickle.load(f)\n"
      ]
      ],
      "id": "73395020",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Implementation\n",
        "Finally, we display the model predictionm on a webpage and take you through our journey of prediction!\n"
      ],
      "id": "ba29e6f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://goto-brought-auction-deck.trycloudflare.com/analyzingtrends/getmatchbyid/1\"  \n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:  # Check if the request was successful\n",
        "    json_data = response.json()  # Convert response to JSON format\n",
        "    print(json_data['season'])  # Print the JSON data\n",
        "else:\n",
        "    print(\"Failed to retrieve data from the API.\")"
      ],
      "id": "9b076f50",
      "execution_count": null,
      "id": "9d23c8b2",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# loaded_model = None\n",
        "\n",
        "# # Load the model from the pickle file\n",
        "# with open(\"/Users/cortmann/Desktop/523 - Data Mining/localCricketPredictions/cricketPrediction.pkl\", \"rb\") as f:\n",
        "#     loaded_model = pickle.load(f)\n",
        "    \n",
        "# predictRFC = loaded_model.predict(X_test)\n",
        "\n",
        "# outcomeRFC = pd.DataFrame ({'Actual': y_test, 'Predicted': predictRFC})\n",
        "# outcomeRFC['Actual'] = label_encoders[9].inverse_transform(outcomeRFC['Actual'])\n",
        "# outcomeRFC['Predicted'] = label_encoders[9].inverse_transform(outcomeRFC['Predicted'])\n",
        "    \n",
        "\n",
        "\n",
        "# cvRF = cross_validate(loaded_model,X_train, y_train)\n",
        "# print(\"cross validation of random forest\", cvRF)\n",
        "# print(\"accuracy of random forest:\", metrics.accuracy_score(y_test, predictRFC)) #testing how accuracy of the models\n",
        "# print(\"precision of random forest:\", metrics.precision_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"recall of random forest:\", metrics.recall_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"f1 of random forest:\", metrics.f1_score(y_test, predictRFC, average = 'weighted'))\n",
        "# print(\"ROCAUC macro of random forest:\", metrics.roc_auc_score(y_test, predictRFC))\n",
        "# print(\"ROCAUC micro of random forest:\", metrics.roc_auc_score(y_test, predictRFC, average = 'micro'))\n",
        "\n",
        "\n",
        "# y_pred_proba = loaded_model.predict_proba(X_test)[::,1]\n",
        "# fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "# plt.plot(fpr,tpr)\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.title('ROC Curve Random Forest')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8395c3",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Layouts\n",
        "\n",
        "You can use plain text\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"40%\"}\n",
        "-   or bullet points[^1]\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "or in two columns\n",
        ":::\n",
        ":::\n",
        "\n",
        "[^1]: And add footnotes\n",
        "\n",
        "-   like\n",
        "\n",
        "-   this\n",
        "\n",
        "## Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0ef776",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LinearRegression\n",
        "# import statsmodels.api as sm\n",
        "# import pandas as pd\n",
        "\n",
        "# # Fit a linear regression model\n",
        "# X = mtcars[['speed']]\n",
        "# y = mtcars['mpg']\n",
        "# model = LinearRegression().fit(X, y)\n",
        "\n",
        "# # Summary of the model\n",
        "# X2 = sm.add_constant(X)\n",
        "# est = sm.OLS(y, X2)\n",
        "# est2 = est.fit()\n",
        "# print(est2.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "472ac439",
      "metadata": {},
      "source": [
        "## Plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce0d9c9",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# penguins['species'] = penguins['species'].apply(lambda x: \"Adelie\" if x == \"Adelie\" else \"Other\")\n",
        "# sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g', hue='species')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7b01229",
      "metadata": {},
      "source": [
        "## Plot and text\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "-   Some text\n",
        "\n",
        "-   goes here\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c641e38",
      "metadata": {
        "fig.width": 5.5,
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# #| warning: false\n",
        "# fig, ax = plt.subplots(figsize=(5.5, 5.5 * 0.618))\n",
        "# sns.boxplot(data=penguins, x='bill_length_mm', y='species', hue='species', ax=ax)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68cd90b0",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        "# A new section...\n",
        "\n",
        "## Tables\n",
        "\n",
        "If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80f78f5",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# penguins.head().to_html()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca0adc3",
      "metadata": {},
      "source": [
        "## Images\n",
        "\n",
        "![Image credit: Danielle Navarro, Percolate.](images/watercolour_sys02_img34_teacup-ocean.png){fig-align=\"center\" width=\"500\"}\n",
        "\n",
        "## Math Expressions {.smaller}\n",
        "\n",
        "You can write LaTeX math expressions inside a pair of dollar signs, e.g. \\$\\\\alpha+\\\\beta\\$ renders $\\alpha + \\beta$. You can use the display style with double dollar signs:\n",
        "\n",
        "```         \n",
        "$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n",
        "```\n",
        "\n",
        "$$\n",
        "\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\n",
        "$$\n",
        "\n",
        "Limitations:\n",
        "\n",
        "1.  The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting `$$` must appear in the very beginning of a line, followed immediately by a non-space character, and the ending `$$` must be at the end of a line, led by a non-space character;\n",
        "\n",
        "2.  There should not be spaces after the opening `$` or before the closing `$`.\n",
        "\n",
        "# Wrap up\n",
        "\n",
        "## Feeling adventurous?\n",
        "\n",
        "-   You are welcomed to use the default styling of the slides. In fact, that's what I expect majority of you will do. You will differentiate yourself with the content of your presentation.\n",
        "\n",
        "-   But some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs."
      ]
      ],
      "id": "9b4d5a13",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
